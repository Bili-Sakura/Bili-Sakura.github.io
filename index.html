<!DOCTYPE HTML>
<html lang="en">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <title>Zhenyuan Chen</title>
    <meta name="author" content="Zhenyuan Chen">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="{{favicon_path}}" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="{{stylesheet_path}}">
</head>

<body>
    <table
        style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
            <tr style="padding:0px">
                <td style="padding:0px">
                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr style="padding:0px">
                                <td style="padding:2.5%;width:63%;vertical-align:middle">
                                    <p class="name" style="text-align: center;">
                                        Zhenyuan Chen
                                    </p>
                                    <p>
                                        I completed my undergraduate studies at Zhejiang University, School of Earth
                                        Science, and am currently a second-year master's student at Zhejiang University,
                                        School of Earth Science.
                                    </p>
                                    <p>
                                        My research interests include the application of multimodal large language
                                        models and diffusion models in remote sensing.
                                    </p>
                                    <p>
                                        You can contact me via email at <a
                                            href="mailto:bili_sakura@zju.edu.cn">bili_sakura@zju.edu.cn</a>.
                                    </p>
                                    <p style="text-align:center">
                                        <a href="mailto:bili_sakura@zju.edu.cn">Email</a> &nbsp;/&nbsp;
                                        <a href="https://github.com/Bili-Sakura">Github</a>
                                    </p>
                                </td>
                                <td class="image">
                                    <a href="assets\profile1.jpg">
                                        <img alt="profile photo" src="assets\profile1.jpg" class="hoverZoomLink"
                                            style="max-width:150px; height:auto;">
                                    </a>
                                </td>
                            </tr>
                        </tbody>
                    </table>

                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:100%;vertical-align:middle">
                                    <h2>Research</h2>
                                    <p>
                                        My research interests include the application of multimodal large language
                                        models and diffusion models in remote sensing.
                                    </p>
                                </td>
                            </tr>
                        </tbody>
                    </table>

                    <!-- Example paper/project entries -->
                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td class="paper-image">
                                    <img src="assets\rscc_teaser.png" alt="RSCC Teaser" style="max-width:300px;">
                                </td>
                                <td style="padding:20px;width:75%;vertical-align:middle">
                                    <a href="https://github.com/Bili-Sakura/RSCC">
                                        <span class="papertitle">RSCC: A Large-Scale Remote Sensing Change Caption
                                            Dataset for Disaster Events</span>
                                    </a>
                                    <br>
                                    <strong>Zhenyuan Chen</strong>,
                                    Chenxi Wang,
                                    Ningyu Zhang,
                                    Feng Zhang
                                    <br>
                                    Zhejiang University
                                    <br>
                                    <em>under review</em>, 2025
                                    <br>
                                    <a href="https://bili-sakura.github.io/RSCC/">project page</a>
                                    <!-- No arXiv link yet -->
                                    <p></p>
                                    <p>
                                        Remote sensing is critical for disaster monitoring, yet existing datasets lack
                                        temporal image pairs and detailed textual annotations. While single-snapshot
                                        imagery dominates current resources, it fails to capture dynamic disaster
                                        impacts over time. To address this gap, we introduce the Remote Sensing Change
                                        Caption (RSCC) dataset, a large-scale benchmark comprising 62,315
                                        pre-/post-disaster image pairs (spanning earthquakes, floods, wildfires, and
                                        more) paired with rich, human-like change captions. By bridging the temporal and
                                        semantic divide in remote sensing data, RSCC enables robust training and
                                        evaluation of vision-language models for disaster-aware bi-temporal
                                        understanding. Our results highlight RSCCâ€™s ability to facilitate detailed
                                        disaster-related analysis, paving the way for more accurate, interpretable, and
                                        scalable vision-language applications in remote sensing. Code and dataset are
                                        available at <a href="https://github.com/Bili-Sakura/RSCC"
                                            target="_blank">https://github.com/Bili-Sakura/RSCC</a>.
                                    </p>
                                </td>
                            </tr>
                        </tbody>
                    </table>

                    <!-- Add further sections as needed, e.g., Miscellanea, Blog Posts, etc., using the same placeholder style -->

                </td>
            </tr>
        </tbody>
    </table>
</body>

</html>